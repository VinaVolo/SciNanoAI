import os
import sys
sys.path.append('..')
import streamlit as st
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from openai import OpenAI
from src.utils.paths import get_project_path

os.environ["OPENAI_API_KEY"] = "—Å—é–¥–∞"
os.environ["OPENAI_API_BASE"] = "—Å—é–¥–∞"

@st.cache_resource()
def load_vector_database(path=os.path.join(get_project_path(), "db", "db_BAAI_bge-m3")):
    """
    Loads a vector database stored in the given path.

    Args:
        path: The path to the vector database.

    Returns:
        A FAISS vector store object.
    """
    embeddings = HuggingFaceEmbeddings(model_name='BAAI/bge-m3')
    vector_store = FAISS.load_local(
        path, embeddings, allow_dangerous_deserialization=True
    )
    return vector_store



def get_rag_response(question, retriever):
    """
    Generates an answer using RAG and OpenAI API.
    """
    relevant_documents = retriever.get_relevant_documents(question)
    context = "\n\n".join(doc.page_content for doc in relevant_documents)

    openai_client = OpenAI(base_url=os.environ["OPENAI_API_BASE"])

    response = openai_client.chat.completions.create(
        model="openai/gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": "You are a highly intelligent assistant who helps find and explain information."
            },
            {
                "role": "user",
                "content": (
                    f"You have access to the following contextual information: {context} "
                    f"Using this information, answer the following question clearly, in detail, and professionally: "
                    f"Question: {question} If the information in the context is insufficient, acknowledge it honestly "
                    "and suggest a logical next step. Answer in Russian."
                )
            },
        ],
        temperature=0.2,
        max_tokens=3000,
    )

    return response.choices[0].message.content.strip()


st.set_page_config(page_title="RAG ChatBot", page_icon="ü§ñ", layout="wide")

st.title("ü§ñ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ ChatBot!")
st.write("–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ —á–∞—Ç-–±–æ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∏—Å–∫–æ–≤–æ-–¥–æ–ø–æ–ª–Ω–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (RAG). –í–æ –º–Ω–µ 301 –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ó–∞–¥–∞–π—Ç–µ –ª—é–±–æ–π –≤–æ–ø—Ä–æ—Å, –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –≤–∞–º –ø–æ–º–æ—á—å!")

retriever = load_vector_database().as_retriever(search_type="similarity", search_kwargs={"k": 5})

user_input = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –∑–¥–µ—Å—å:")

if user_input:
    with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞..."):
        try:
            response = get_rag_response(user_input, retriever)
            st.write(response)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
